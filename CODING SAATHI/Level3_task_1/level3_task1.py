# -*- coding: utf-8 -*-
"""Level3_task1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oEhs2b018Mup7tXqjIdyydhuxGa2V1o4

#Import Modules
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.datasets import mnist
from sklearn.metrics import confusion_matrix
import numpy as np

"""#Load the MNIST dataset"""

(x_train, y_train), (x_test, y_test) = mnist.load_data()

"""#Data Pre-Processing

"""

# Reshape the data to be in the format expected by the CNN
x_train = x_train.reshape(-1, 28, 28, 1)
x_test = x_test.reshape(-1, 28, 28, 1)

# Normalize the pixel values (to ease computation)
x_train = x_train / 255.0
x_test = x_test / 255.0

"""# Defining the CNN model architecture

"""

# Define the CNN model architecture
model = keras.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10)
])

"""# Compile the model"""

# Compile the model
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

"""#Train the model on the MNIST dataset"""

model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))

# Save the trained model to disk
model.save('mnist_cnn_model.h5')

# Load the saved model from disk
loaded_model = keras.models.load_model('mnist_cnn_model.h5')

"""# Test the model on a test image"""

# Test the loaded model on a test image
y_pred = model.predict(x_test)#model.predict() gives the prediction probability of each class for that data point
print(y_pred,y_pred.shape)

# converting the prediction probabilities to class label
label_for_first_test_image = np.argmax(y_pred[0])
print(label_for_first_test_image)

# converting the prediction probabilities to class label for all test data points
y_pred_labels = [np.argmax(i) for i in y_pred]
print(y_pred_labels)

#Accuracy on Test data:
loss, accuracy = model.evaluate(x_test, y_test)
print('Accuracy score ',accuracy)
print(x_test.shape)

"""# Confusion matrix"""

conf_mat = confusion_matrix(y_test, y_pred_labels)
import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize=(15,7))
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')
plt.ylabel('True Labels')
plt.xlabel('Predicted Labels')
plt.show()

"""# Testing the model on a random image"""

test_image = x_test[10]
prediction = loaded_model.predict(np.array([test_image])) #model.predict() gives the prediction probability of each class for that data point
import cv2
plt.imshow(test_image)
print("True label",y_test[10])
print('predicted label ',np.argmax(prediction[0]))